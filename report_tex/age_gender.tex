Эта часть выполнена Алексеем Биршертом. \\

\subsection{Описание метода}\label{subsec:описание-метода}
Для предсказания пола и возраста используются две модели, состоящих из основной и выходной моделей каждая.
В качестве основной модели используется глубокая нейронная сеть ResNet-18, без последнего полносвязного слоя.
В качестве выходной модели используется персептрон из двух полносвязных слоёв с нелинейностью ReLU и дропаутом между ними.
Первая модель предназначена для классификации пола и имеет в выходной модели 512 и 256 входных и выходных нейронов в первом слое, 256 и 2 во втором соответственно.
Вторая модель предназначена для классификации возраста и имеет в выходной модели 512 и 512 входных и выходных нейронов в первом слое, 512 и 101 во втором соответственно.
На вход подаются фотографии лиц людей, выделенные и выровненные с помощью модели детектирования лиц,
размером 227 на 227 пикселей, 3 канала цвета - R, G, B\@.
Предсказанный пол определяется с помощью определения выходного нейрона соответсвующей нейронной сети с максимальным значением -
первый это "женский", второй "мужской".
Предсказанный возраст определяется следующим образом: сначала для вектора значений выходных нейронов
соответсвующей нейронной сети применяется преобразование софтмакс, затем значения умножаются на соответствующий
им возраст.
После вектор суммируется - получаем матожидание возраста при вероятностном распределении, выданном моделью.
$AGE = \sum\limits_{i = 0}^{100}i \cdot softmax(x)_i, \quad softmax(x)_i = \frac{\exp(x_i)}{\sum\limits_{j =
0}^{100}\exp(x_j)}$.

\subsection{Описание данных}\label{subsec:описание-данных}
В качестве датасета для обучения двух вышеописанных моделей были избраны датасеты IMDB-WIKI-101 и FGNET\@.
Распределение реального возраста в датасете IMDB-WIKI-101 имеет вид нормальной кривой со средним около 35 лет,
имея малое количество объектов с возрастом меньше 10 лет или больше 90.
% TODO: возможно картинка с распределением возраста в датасете
Для восполнения данных по возрасту до 10 лет был избран датасет FGNET, в котором большая часть объектов это дети до 15 лет.
Для улучшения сходимости нейронных сетей была произведена предобработка всех объектов -
в итоговую выборку не были включены следующие объекты:
объекты с плохо различимыми лицами (показатель уверенности модели распознавания лиц в том, что это лицо, ниже фиксированного значения),
объекты с некорректно заполненными данными по полу/возрасту,
объекты со слишком маленькими фотографиями.
Для каждого объекта были выделены мета-данные про пол и возраст, а так же детектировано и выделено лицо.
Отступ от границы лица был поставлен 40\%, чтобы можно было полностью получить лицо внутри квадрата.
Итого было получено около 200 тысяч объектов, которые были в дальнейшем поделены
с сохранением баланса классов 1 к 19 на валидационную и обучающую выборки соответственно.
В качестве датасета для тестирования был избран датасет Adience, по которому известно большое количество результатов различных моделей.
Из него были исключены объекты с некорректным описанием пола или возраста.
Итого было получено почти 11 тысяч объектов для тестовой выборки.
В Adience метки возраста в формате 8 групп - 0: [0, 2], 1: [4, 6], 2: [8, 12], 3: [15, 20], 4: [25, 32], 5: [38, 43], 6: [48, 53], 7: [60, 100].
% TODO: возможно картинка с распределением возраста в датасете
В связи с этим, необходимо было решить как относить к этим группам метки реального возраста от 0 до 100.
Было принято решение относить к ближайшей группе - например, 22 года ближе к 20, чем к 25, следовательно
относится к группе 3: [15, 20].
В случае одинакового расстояния выбиралась первая по порядку группа.

\subsection{Постановка задач обучения}\label{subsec:постановка-задач-обучения}
Задача классификации пола является задачей бинарной классификации, целевая переменная для одного объекта это число 0 или 1.
Для обучения была выбрана перекрестная энтропия - функция ошибки со следующей формулой:
$loss(x, y) = -x_y + \log\left(\sum\limits_{j=1}^{K}\exp(x_j)\right)$, где $x$ - вектор значений выходных нейронов нейронной сети, $y$ - целевая переменная.
Для оценки качества классификации использовались метрика доля правильных ответов (далее accuracy), так как выборки сбалансированны по полу.
\newline
Задача классификации возраста является задачей многоклассовой классификации.
Если смотреть на задачу предсказания возраста по фотографии с точки зрения человека,
человек гораздо точнее способен угадать диапазон возраста, нежели точный возраст.
Поэтому задача классификации возраста была интерпретирована как задача с множественными правильными ответами -
каждому объекту может соответствовать набор правильных классов.
Целевой переменной для одного объекта служил вектор из нулей и единиц, единицы на позициях правильных классов.
Правильные классы определялись как значения возраста, которые отличаются по модулю от правильного не больше,
чем на фиксированное число, которое было гиперпараметром (далее об этом в разделе эксперименты (\ref{subsec:эксперименты})).
Для обучения была выбрана бинарная перекрестная энтропия -
$loss(x, y) = sum(L), \quad L = \{l_1, \dots l_N\}, \quad l_i = \left(y_i \log(x_i) + (1 - y_i) \log(1 - x_i)\right)$,
где $x$ это вектор значений выходных нейронов нейронной сети после применения сигмоидного преобразования,
$y$ - целевая переменная.
Для оценки качества классификации использовались средний модуль отклонения (далее MAE)
и доля объектов, у которых MAE не превышает фиксированного числа (далее CS-5).

\subsection{Эксперименты}\label{subsec:эксперименты}
Первым необходимо было решить вопрос архитектуры базовой модели, было принято решение остановиться на ResNet-18.
Всего было опробовано четыре различных архитектуры - MobileNet, ShuffleNet, ResNet и
нейронная сеть с тремя сверточными слоями с нормализацией~\cite{LRN} между слоями и активацией ReLU и последующими двумя полносвязными слоями.
Лучше всего себя проявила архитектура ResNet-18.
MobileNet и ShuffleNet оказались не сильно быстрее, не смотря на реализацию, однако достаточно сильно проигрывали в качестве.
Простая нейронная сеть из трёх слоёв оказалась медленнее ResNet в силу больших размеров изображений и огромного размера полносвязного слоя.
Из-за этого она очень плохо и медленно сходилась и показывала самые плохие результаты.
Графики сравнения появятся чуть позже.
% TODO возможно графики.
\par Так как ResNet-18 предобучен на датасете ImageNet-1000, он имеет очень хорошую способность выделять признаки из изображения.
Известно, что первые (входные) сверточные слои очень похожи между собой даже для различных задач.
Таким образом, было решено первый сверточный слой ResNet-18 заморозить в процессе обучения, дообучать все остальные и полносвязные в конце.
\par Вторым необходимо было решить вопрос количества моделей - одна модель с общей базовой моделью и двумя паралелльными выходными моделями
или две отдельные модели из основной и выходной модели.
В итоге лучше себя показала конструкция из двух отдельных моделей, в силу использования функций ошибки,
которые имеют разный масштаб и решают частично разные задачи на моменте основной модели,
и сложности в подборе гиперпараметров модель из одной общей основной модели очень плохо сходилась к локальным минимумам.
Графики сравнения появятся чуть позже.
% TODO возможно графики.
\par В процессе подбора гиперпараметров были выбраны следующие значения: темп обучения был выставлен на $1e-3$ для первых 20 эпох,
далее $1e-4$ для модели предсказания возраста, $1e-4$ для первых 30 эпох и $2e-5$ далее для модели предсказания пола;
коэффициент регуляризации был установлен на $1e-3$ для обеих моделей;
размер батча изображений 128;
размер входных картинок 227 на 227 пикселей;
дропаут 0.1 перед 4 слоём ResNet, 0.2 перед первым полносвязным слоём и 0.4 между слоями.
В качестве размера окна для правильного возраста после сравнений было выбрано число в 5 лет.
\par В процессе выбора аугментации были выбраны следующие трансформации -
для обучения каждое изображение преобразовывалось к квадрату 256 на 256 пикселей,
затем из него выбирался случайный квадрат со стороной 227 пикселей,
который с вероятностью 0.5 мог быть отзеркален вдоль вертикальной оси, проходящей через его центр.
Для тестирования каждое изображение преобразовывалось к квадрату 256 на 256 пикселей,
затем из него вырезался квадрат со стороной 227 пикселей из центра.

\subsection{Результаты}\label{subsec:результаты}
В итоге получилось достичь следующих показателей метрик на обучающей и валидационной выборках: для возраста MAE 4 и 4.3 соответственно,
CS-5 0.8 и 0.76 соответственно, для пола Accuracy 0.95 и 0.94 соответственно.
\par Модель показала следующие результаты на датасете Adience: для возраста Exact-accuracy 45\% и One-off-accuracy 80\%,
для пола значение метрики Accuracy 85\%.
\par В этой подглаве планируется показать примеры удачных и неудачных распознаваний и сравнить результаты с тремя статьями.
Уже можно сказать, что одну результат одной статьи удалось превзойти, к результатам двух других приблизиться снизу.
\par Всего было написано более 2300 строк кода на языке программирования Python3,
все модели были написаны и обучены с использованием фреймворка машинного обучения PyTorch.